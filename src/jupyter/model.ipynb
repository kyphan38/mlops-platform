{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ae9cb6b6-0de4-4f36-a291-47fb8dbf88a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of dataframe: 260369\n",
      "\n",
      "Column: id, Missing Values: 0, Type: int64\n",
      "Column: host_id, Missing Values: 0, Type: int64\n",
      "Column: property_type, Missing Values: 0, Type: object\n",
      "Column: room_type, Missing Values: 0, Type: object\n",
      "Column: accommodates, Missing Values: 0, Type: float64\n",
      "Column: bathrooms, Missing Values: 0, Type: float64\n",
      "Column: bedrooms, Missing Values: 0, Type: float64\n",
      "Column: beds, Missing Values: 0, Type: float64\n",
      "Column: price, Missing Values: 0, Type: float64\n",
      "Column: has_availability, Missing Values: 0, Type: object\n",
      "Column: availability_30, Missing Values: 0, Type: float64\n",
      "Column: availability_60, Missing Values: 0, Type: float64\n",
      "Column: availability_90, Missing Values: 0, Type: float64\n",
      "Column: availability_365, Missing Values: 0, Type: float64\n",
      "Column: instant_bookable, Missing Values: 0, Type: object\n",
      "Column: host_response_time, Missing Values: 0, Type: object\n",
      "Column: host_response_rate, Missing Values: 0, Type: float64\n",
      "Column: host_acceptance_rate, Missing Values: 0, Type: float64\n",
      "Column: host_is_superhost, Missing Values: 0, Type: object\n",
      "Column: host_listings_count, Missing Values: 0, Type: float64\n",
      "Column: host_total_listings_count, Missing Values: 0, Type: float64\n",
      "Column: host_verifications, Missing Values: 141, Type: object\n",
      "Column: host_has_profile_pic, Missing Values: 0, Type: object\n",
      "Column: host_identity_verified, Missing Values: 0, Type: object\n",
      "Column: number_of_reviews, Missing Values: 0, Type: float64\n",
      "Column: number_of_reviews_ltm, Missing Values: 0, Type: float64\n",
      "Column: number_of_reviews_l30d, Missing Values: 0, Type: float64\n",
      "Column: review_scores_rating, Missing Values: 0, Type: float64\n",
      "Column: review_scores_accuracy, Missing Values: 0, Type: float64\n",
      "Column: review_scores_cleanliness, Missing Values: 0, Type: float64\n",
      "Column: review_scores_checkin, Missing Values: 0, Type: float64\n",
      "Column: review_scores_communication, Missing Values: 0, Type: float64\n",
      "Column: review_scores_location, Missing Values: 0, Type: float64\n",
      "Column: review_scores_value, Missing Values: 0, Type: float64\n",
      "Column: reviews_per_month, Missing Values: 0, Type: float64\n",
      "Column: minimum_nights, Missing Values: 0, Type: float64\n",
      "Column: maximum_nights, Missing Values: 0, Type: float64\n",
      "Column: minimum_minimum_nights, Missing Values: 0, Type: float64\n",
      "Column: maximum_minimum_nights, Missing Values: 0, Type: float64\n",
      "Column: minimum_maximum_nights, Missing Values: 0, Type: float64\n",
      "Column: maximum_maximum_nights, Missing Values: 0, Type: float64\n",
      "Column: minimum_nights_avg_ntm, Missing Values: 0, Type: float64\n",
      "Column: maximum_nights_avg_ntm, Missing Values: 0, Type: float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment dev_model5 already exists.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/_distutils_hack/__init__.py:18: UserWarning: Distutils was imported before Setuptools, but importing Setuptools also replaces the `distutils` module in `sys.modules`. This may lead to undesirable behaviors or errors. To avoid these issues, avoid using distutils directly, ensure that setuptools is installed in the traditional way (e.g. not an editable install), and/or make sure that setuptools is always imported before distutils.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/_distutils_hack/__init__.py:33: UserWarning: Setuptools is replacing distutils.\n",
      "  warnings.warn(\"Setuptools is replacing distutils.\")\n",
      "/opt/conda/lib/python3.11/importlib/__init__.py:126: DeprecationWarning: The distutils package is deprecated and slated for removal in Python 3.12. Use setuptools or check PEP 632 for potential alternatives\n",
      "  return _bootstrap._gcd_import(name[level:], package, level)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run_id: c182879fc05349fe8a8a716bf137b29f\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from sqlalchemy import create_engine\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "from feast import FeatureStore\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "\n",
    "from sklearn.preprocessing import OrdinalEncoder, RobustScaler, PolynomialFeatures\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, BayesianRidge, ElasticNet\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "\n",
    "from utils.model.feature_vars import listing_features, host_features, review_features, fact_features\n",
    "from utils.model.feast import query_data, get_historical_features\n",
    "from utils.model.checking import df_description\n",
    "from utils.model.outliers import outliers_handling\n",
    "from utils.model.encoding import data_encoding\n",
    "from utils.mlflow.creating import create_mlflow_experiment\n",
    "\n",
    "db_config = {\n",
    "  'user': 'admin',\n",
    "  'password': 'admin123',\n",
    "  'host': 'feast_postgres',\n",
    "  'port': '5432',\n",
    "  'database': 'feast_postgres'\n",
    "}\n",
    "\n",
    "def data_extraction():\n",
    "  fs = FeatureStore(repo_path=\"./feature_repo\")\n",
    "\n",
    "  connection_string = f\"postgresql://{db_config['user']}:{db_config['password']}@{db_config['host']}:{db_config['port']}/{db_config['database']}\"\n",
    "  engine = create_engine(connection_string)\n",
    "\n",
    "  queries = {\n",
    "    'listing': \"SELECT id, event_timestamp FROM listing_table\",\n",
    "    'host': \"SELECT host_id, event_timestamp FROM host_table\",\n",
    "    'review': \"SELECT id, event_timestamp FROM review_table\",\n",
    "    'fact': \"SELECT id, event_timestamp FROM fact_table\"\n",
    "  }\n",
    "\n",
    "  with ThreadPoolExecutor() as executor:\n",
    "    listing_data, host_data, review_data, fact_data = executor.map(lambda q: query_data(engine, q), queries.values())\n",
    "\n",
    "  listing_df = get_historical_features(fs, listing_data, listing_features)\n",
    "  host_df = get_historical_features(fs, host_data, host_features)\n",
    "  review_df = get_historical_features(fs, review_data, review_features)\n",
    "  fact_df = get_historical_features(fs, fact_data, fact_features)\n",
    "\n",
    "  # Drop event_timestamp columns\n",
    "  for df in [listing_df, host_df, review_df, fact_df]:\n",
    "    df.drop(columns=['event_timestamp'], inplace=True)\n",
    "\n",
    "  # Merge dataframes\n",
    "  df = pd.merge(listing_df, host_df, on=\"host_id\", how=\"left\").drop_duplicates(subset=['id'])\n",
    "  df = pd.merge(df, review_df, on=\"id\", how=\"left\").drop_duplicates(subset=['id'])\n",
    "  df = pd.merge(df, fact_df, on=\"id\", how=\"left\").drop_duplicates(subset=['id'])\n",
    "\n",
    "  print(f\"Length listing_df {len(listing_df)}\")\n",
    "  print(f\"Length host_df {len(host_df)}\")\n",
    "  print(f\"Length review_df {len(review_df)}\")\n",
    "  print(f\"Length fact_df {len(fact_df)}\")\n",
    "  print(f\"Length df {len(df)}\")\n",
    "\n",
    "  df.to_csv(\"./data.csv\", index=False)\n",
    "\n",
    "  return df\n",
    "\n",
    "def data_validation(df):\n",
    "  report = {}\n",
    "\n",
    "  missing_values_count = df.isnull().sum()\n",
    "  vals = []\n",
    "\n",
    "  print(f\"Length of dataframe: {len(df)}\\n\")\n",
    "\n",
    "  for col in df.columns:\n",
    "    missing_count = missing_values_count[col]\n",
    "    col_type = df[col].dtype\n",
    "    vals.append(f\"Column: {col}, Missing Values: {missing_count}, Type: {col_type}\")\n",
    "\n",
    "  vals = \"\\n\".join(vals)\n",
    "  print(vals)\n",
    "\n",
    "  return df\n",
    "\n",
    "\n",
    "def data_preparation(df):\n",
    "  # Outliers handling\n",
    "  df = outliers_handling(df)\n",
    "\n",
    "  # Data encoding\n",
    "  df = data_encoding(df)\n",
    "\n",
    "  # Data splitting\n",
    "  features = df.drop(\"price\", axis=1)\n",
    "  target = df[\"price\"]\n",
    "  X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.3, random_state=42)\n",
    "\n",
    "  # Data standardizing\n",
    "  scaler = RobustScaler()\n",
    "  X_train_scaled = scaler.fit_transform(X_train)\n",
    "  X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "  return X_train_scaled, X_test_scaled, y_train, y_test\n",
    "\n",
    "def model_training(X_train_scaled, y_train):\n",
    "  models_and_params = {\n",
    "    \"Linear_Regression\": LinearRegression(),\n",
    "    \"Ridge_Regression\": Ridge(alpha=0.001),\n",
    "    \"Lasso_Regression\": Lasso(alpha=0.0001),\n",
    "    \"Bayesian_Ridge Regression\": BayesianRidge(alpha_1=1e-6, lambda_1=1e-6),\n",
    "    \"ElasticNet_Regression\": ElasticNet(alpha=0.01, l1_ratio=0.2),\n",
    "    \"Decision_Tree_Regression\": DecisionTreeRegressor(max_depth=3),\n",
    "  }\n",
    "\n",
    "  trained_models = {}\n",
    "  for name, model in models_and_params.items():\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "    trained_models[name] = model\n",
    "\n",
    "  return trained_models\n",
    "\n",
    "def model_scoring(trained_models, X_test_scaled, y_test):\n",
    "  res = []\n",
    "  for name, model in trained_models.items():\n",
    "    predictions = model.predict(X_test_scaled)\n",
    "    rmse = mean_squared_error(y_test, predictions, squared=False)\n",
    "    r2 = r2_score(y_test, predictions)\n",
    "    res.append((name, model, model.get_params(), rmse, r2))\n",
    "\n",
    "  return res\n",
    "\n",
    "def model_exporting(res):\n",
    "    mlflow.set_tracking_uri(\"http://mlflow:5000\")\n",
    "    experiment_id = create_mlflow_experiment(\n",
    "      experiment_name=\"dev_model5\",\n",
    "      artifact_location=\"s3://artifacts\"\n",
    "    )\n",
    "\n",
    "    with mlflow.start_run(run_name=\"experiment\", experiment_id=experiment_id) as run:\n",
    "        for name, model, params, rmse, r2 in res:\n",
    "            with mlflow.start_run(run_name=name, nested=True) as run: \n",
    "                mlflow.log_params(params)\n",
    "                mlflow.log_metric(\"rmse\", rmse)\n",
    "                mlflow.log_metric(\"r2\", r2)\n",
    "                mlflow.sklearn.log_model(model, artifact_path=name)\n",
    "        print(\"run_id: {}\".format(run.info.run_id))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "  # df = data_extraction()\n",
    "  df = pd.read_csv(\"./data.csv\")\n",
    "  df = data_validation(df)\n",
    "  X_train_scaled, X_test_scaled, y_train, y_test = data_preparation(df)\n",
    "  trained_models = model_training(X_train_scaled, y_train)\n",
    "  res = model_scoring(trained_models, X_test_scaled, y_test)\n",
    "  \n",
    "  model_exporting(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b5bf3fb4-88b3-4727-8dad-62a64efacca1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading artifacts: 100%|██████████| 9/9 [00:00<00:00, 178.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeRegressor(max_depth=3)\n",
      "Mean Squared Error: 0.06186771565588156\n",
      "R-squared: 0.43592440245415187\n",
      "[2.13300986 2.26056703 2.13300986 ... 2.13300986 2.1445345  2.74485902]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model_uri = \"mlflow-artifacts:/66/c182879fc05349fe8a8a716bf137b29f/artifacts/Decision_Tree_Regression\"\n",
    "DTG = mlflow.sklearn.load_model(model_uri=model_uri)\n",
    "print(DTG)\n",
    "\n",
    "# Make predictions on the old data\n",
    "predictions = DTG.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate predictions if actual values are available\n",
    "mse = mean_squared_error(y_test, predictions)\n",
    "r2 = r2_score(y_test, predictions)\n",
    "\n",
    "print(f\"Mean Squared Error: {mse}\")\n",
    "print(f\"R-squared: {r2}\")\n",
    "\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "405fb3c6-8b6e-4bad-b58d-a6e3b0d0e2b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastapi import FastAPI, HTTPException\n",
    "from pydantic import BaseModel\n",
    "import mlflow.sklearn\n",
    "from typing import List\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "app = FastAPI()\n",
    "\n",
    "# Load the trained model\n",
    "model_uri = \"mlflow-artifacts:/66/c182879fc05349fe8a8a716bf137b29f/artifacts/Decision_Tree_Regression\"\n",
    "DTG = mlflow.sklearn.load_model(model_uri=model_uri)\n",
    "\n",
    "class PredictionRequest(BaseModel):\n",
    "    data: List[List[float]]\n",
    "\n",
    "class PredictionResponse(BaseModel):\n",
    "    predictions: List[float]\n",
    "    mse: float = None\n",
    "    r2: float = None\n",
    "\n",
    "@app.post(\"/predict\", response_model=PredictionResponse)\n",
    "async def predict(request: PredictionRequest):\n",
    "    try:\n",
    "        # Convert the input data to a DataFrame\n",
    "        input_data = pd.DataFrame(request.data)\n",
    "        \n",
    "        # Assume X_test_scaled is preprocessed similarly\n",
    "        # This part may vary depending on how you scale your input data\n",
    "        X_test_scaled = input_data  # Adjust this line as needed\n",
    "\n",
    "        # Make predictions\n",
    "        predictions = DTG.predict(X_test_scaled)\n",
    "\n",
    "        return PredictionResponse(\n",
    "            predictions=predictions.tolist()\n",
    "        )\n",
    "    except Exception as e:\n",
    "        raise HTTPException(status_code=500, detail=str(e))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    import uvicorn\n",
    "    uvicorn.run(app, host=\"127.0.0.1\", port=8000, reload=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51f0d9ee-9996-436a-aa1c-3db7d6f70e57",
   "metadata": {},
   "outputs": [],
   "source": [
    "!uvicorn main:app --reload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74e82b43-b71e-4dc9-bb43-7bbbf4bcd8c3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
